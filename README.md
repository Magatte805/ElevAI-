# ElevAI â€“ Plateforme dâ€™analyse du bien-Ãªtre quotidien
## PrÃ©sentation du projet

ElevAI est une application web complÃ¨te (frontend + backend) permettant dâ€™analyser le bien-Ãªtre quotidien dâ€™un utilisateur Ã  partir de donnÃ©es personnelles telles que :

- le sommeil,
- lâ€™activitÃ© physique,
- le stress,
- lâ€™humeur,
- la frÃ©quence cardiaque.

GrÃ¢ce Ã  un modÃ¨le de Machine Learning, lâ€™application calcule :
- un score global de bien-Ãªtre,
- une Ã©valuation qualitative (faible, moyen, bon, excellent),
- des recommandations personnalisÃ©es,
- des analyses visuelles (graphiques, radar, historique).

Le projet vise Ã  sensibiliser lâ€™utilisateur Ã  ses habitudes de vie et Ã  lâ€™aider Ã  les amÃ©liorer de maniÃ¨re simple et visuelle.

## ğŸ¯ Objectifs du projet:
- Collecter des donnÃ©es de santÃ© quotidiennes
- Analyser ces donnÃ©es avec un modÃ¨le ML
- Produire un score normalisÃ© (0â€“100 %)
- GÃ©nÃ©rer des recommandations personnalisÃ©es
- Visualiser les rÃ©sultats via un dashboard interactif
- Proposer une architecture claire frontend / backend

## Architecture du projet 
```bash
ElevAI/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Point dâ€™entrÃ©e FastAPI
â”‚   â”œâ”€â”€ database.py            # Configuration base de donnÃ©es
â”‚   â”œâ”€â”€ models.py              # ModÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ schemas.py             # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ crud.py                # Logique mÃ©tier (CRUD)
â”‚   â”œâ”€â”€ tables.py              # CrÃ©ation des tables Ã  partir des modÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ requirements.txt       # DÃ©pendances backend
    â””â”€â”€ test_models.py
â”‚   â””â”€â”€test_endpoints.py
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/               # Routes de lâ€™API
â”‚   â”‚   â”œâ”€â”€ users.py           # Authentification & utilisateurs
â”‚   â”‚   â”œâ”€â”€data.py            # DonnÃ©es quotidiennes
â”‚   â”‚   â””â”€â”€ analysis.py        # Analyse ML, score, anomalies
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                    # Machine Learning
â”‚   â”‚   â”œâ”€â”€ train.py           # EntraÃ®nement du modÃ¨le
â”‚   â”‚   â””â”€â”€ model.pkl          # ModÃ¨le entraÃ®nÃ©
â”‚   â”‚
â”‚                
â”‚      
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # Composants rÃ©utilisables
â”‚   â”‚   â”œâ”€â”€ pages/             # Pages principales
â”‚   â”‚   â””â”€â”€ utils/             # Fonctions utilitaires
        â””â”€â”€ app.jsx  
        â””â”€â”€ api.js                  
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json           # DÃ©pendances frontend
â”‚   â””â”€â”€ vite.config.js         # Configuration Vite
    â””â”€â”€ tests/                 # Les tests plawright
    
â”‚
â””â”€â”€ README.md                  # Documentation du projet
```
## âš™ï¸ PrÃ©requis
Outils nÃ©cessaires : 
- Node.js â‰¥ 18
- Python â‰¥ 3.10
- pip
- Git

## Comment lancer le site?

### Ã‰tape 1â€¯: Cloner le projet
```bash
git clone "https://github.com/Magatte805/ElevAI-.git"
```

## Lancement du projet
AprÃ¨s avoir clonÃ© le projet et ouvert le dossier dans votre Ã©diteur (VS Code par exemple), voici les Ã©tapes pour pouvoir lancer le projet correctement.

### 1. Installer les dÃ©pendances du backend
Le backend est basÃ© sur Python et utilise FastAPI pour lâ€™API REST. Il contient :
- Gestion des utilisateurs et authentification
- Gestion des donnÃ©es quotidiennes de lâ€™utilisateur
- Analyse des donnÃ©es avec un modÃ¨le de Machine Learning
- CRUD complet pour interagir avec la base de donnÃ©es

Librairies principales Ã  installer (dÃ©jÃ  listÃ©es dans requirements.txt)â€¯:
- fastapi : framework pour crÃ©er lâ€™API REST
- uvicorn : serveur pour exÃ©cuter FastAPI
- sqlalchemy : gestion de la base de donnÃ©es
- pydantic : validation des donnÃ©es
- pytest : pour les tests
- joblib : pour charger le modÃ¨le ML
- numpy, pandas : manipulation de donnÃ©es

### Installationâ€¯:
``` bash
# Se placer dans le dossier racine du projet
cd ELEVAI-
# Installer les dÃ©pendances
pip install -r backend/requirements.txt
```
#### Remarque si pip ne fonctionne pas
- Sur certaines machines, pip peut ne pas Ãªtre reconnu.
- Dans ce cas, utilisez une des commandes suivantes selon votre configurationâ€¯:

```bash
py -m pip install -r backend/requirements.txt
# ou
python -m pip install -r backend/requirements.txt
```

### 2. Lancer le backend
Le point dâ€™entrÃ©e de lâ€™application backend est app.py dans le dossier backend.
Le backend doit Ãªtre lancÃ© depuis le dossier racine du projet (ElevAi).
Se placer dans le dossier ElEVAI- (si ce nâ€™est pas dÃ©jÃ  fait) :
```bash
# Lancer le serveur FastAPI
uvicorn backend.app:app --reload
```
#### Remarque si la commande uvicorn ne fonctionne pas
- Sur certaines machines vous pouvez obtenir une erreur Â« uvicorn : Le terme nâ€™est pas reconnu Â».
- Dans ce cas, utilisez une des commandes suivantesâ€¯:
```bash
py -m uvicorn backend.app:app --reload
# ou
python -m uvicorn backend.app:app --reload
```
- Par dÃ©faut, le backend tourne sur http://127.0.0.1:8000.
- Vous pouvez tester que lâ€™API fonctionne en ouvrant http://127.0.0.1:8000/docs dans votre navigateur pour accÃ©der Ã  la documentation interactive.

### 3. Lancer le frontend
Le frontend est dÃ©veloppÃ© avec React et permet dâ€™afficher le dashboard interactif avec toutes les visualisations (score, radar, recommandations, Ã©volution des scores, prÃ©visions, anomaliesâ€¦).

ğŸ’¡ Astuceâ€¯: ouvrez deux terminaux cÃ´te Ã  cÃ´te. Dans lâ€™un vous lancez le backend, dans lâ€™autre le frontend.

#### a. Installer les dÃ©pendances
Le frontend utilise plusieurs librairiesâ€¯:
- react / react-dom : base du projet React
- react-router-dom : navigation entre pages
- recharts : graphiques et visualisations
- axios : appels API vers le backend
- tailwindcss / shadcn/ui : styles et composants

##### Installationâ€¯:
```bash
# Se placer dans le dossier frontend
cd frontend

# Installer les dÃ©pendances Node.js
npm install
```
âš ï¸ Assurez-vous dâ€™avoir Node.js â‰¥ 18 et npm installÃ©s sur votre machine.

#### b. Lancer le frontend
```bash
# Dans le terminal du frontend
npm run dev
```
- Le projet va sâ€™ouvrir automatiquement sur http://localhost:5173/.
- Vous arriverez dâ€™abord sur la page dâ€™accueil avec deux boutonsâ€¯: Se connecter ou Sâ€™inscrire.
- AprÃ¨s la connexion, vous accÃ©derez Ã  la page pour ajouter votre journÃ©e et vous avez un bouton pour accÃ©der au dashboard oÃ¹ toutes les visualisations interagissent avec le backend.

## VÃ©rification
- Backend sur http://127.0.0.1:8000
- Frontend sur http://localhost:5173
- Les deux doivent tourner simultanÃ©ment pour que lâ€™application fonctionne correctement.

## Les tests playwright
Les tests frontend simulent le parcours complet dâ€™un utilisateur dans lâ€™application.

Ils vÃ©rifient notamment :
- la crÃ©ation dâ€™un utilisateur et la redirection,
- lâ€™ajout dâ€™une journÃ©e de donnÃ©es,
- lâ€™affichage du score et des recommandations,
- la mise Ã  jour du graphique dâ€™Ã©volution.

ğŸ“Œ PrÃ©requis
- Le backend doit Ãªtre lancÃ© 
- Le frontend doit Ãªtre lancÃ© 

ğŸ“Œ Lancer les tests 
Les tests doivent Ãªtre lancÃ©s dans un autre terminal, une fois le backend et le frontend dÃ©marrÃ©s.

1. Se placer dans le dossier frontend
```bash
cd frontend
```

2. Installer Playwright
```bash
npx playwright install
```

3. Lancer les tests
```bash
npx playwright test --reporter=html
```


## Questions de rÃ©flexion

### 1.Pourquoi avoir choisi ce type de modÃ¨le ? Quelles alternatives envisagÃ©es ?

Nous avons choisi un **RandomForestRegressor** car il est bien adaptÃ© Ã  notre problÃ¨me de prÃ©diction dâ€™un score Ã  partir de donnÃ©es hÃ©tÃ©rogÃ¨nes (sommeil, pas, sport, humeur, stress, etc.).
Les principales raisons de ce choix sont :
- il gÃ¨re bien les **relations non linÃ©aires** entre les variables,
- il est **robuste au bruit** et aux petites variations des donnÃ©es,
- il fonctionne correctement mÃªme avec un **jeu de donnÃ©es de taille limitÃ©e**,
- il ne nÃ©cessite pas dâ€™hypothÃ¨ses fortes sur la distribution des donnÃ©es.

De plus, le Random Forest permet dâ€™analyser lâ€™**importance des features**, ce qui est intÃ©ressant pour expliquer les rÃ©sultats Ã  lâ€™utilisateur.

**Alternatives envisagÃ©es :**

-  **RÃ©gression linÃ©aire** : trop simpliste pour capturer les relations complexes entre les variables.
-  **Gradient Boosting / XGBoost** : potentiellement plus performant, mais plus complexe Ã  rÃ©gler.
- **RÃ©seaux de neurones** : nÃ©cessitent plus de donnÃ©es et sont moins interprÃ©tables pour ce type dâ€™application.

### 2. Comment gÃ©rer lâ€™Ã©chelle naturelle des features (ex : pas vs humeur) ?

Les features ont des Ã©chelles trÃ¨s diffÃ©rentes :
- `pas` : valeurs Ã©levÃ©es (milliers),
- `humeur` et `stress` : Ã©chelle rÃ©duite (0 Ã  5),
- `sommeil_h` ou `sport_min` : valeurs intermÃ©diaires.

Pour Ã©viter quâ€™une feature domine les autres, nous appliquons une **standardisation** des donnÃ©es avec `StandardScaler` :
- centrage des donnÃ©es autour de 0,
- rÃ©duction Ã  une variance unitaire.


### 3. Quelles mÃ©triques dâ€™Ã©valuation sont pertinentes pour votre approche ?

Le problÃ¨me est un **problÃ¨me de rÃ©gression**, les mÃ©triques pertinentes sont donc :
-  **MAE (Mean Absolute Error)** : mesure lâ€™erreur moyenne, facile Ã  interprÃ©ter.
- **RMSE (Root Mean Squared Error)** : pÃ©nalise davantage les grandes erreurs.
- **RÂ² score** : indique la proportion de variance expliquÃ©e par le modÃ¨le.

### 4. Comment assurer la reproductibilitÃ© (random_state, versions, seeds) ?

La reproductibilitÃ© est assurÃ©e par plusieurs Ã©lÃ©ments :

- lâ€™utilisation dâ€™un **`random_state=42`** dans le `RandomForestRegressor`,
- la sÃ©paration claire entre donnÃ©es, preprocessing et modÃ¨le,
- la sauvegarde du modÃ¨le et du scaler avec `pickle`,
- le versioning du code via **Git**,
- la liste des dÃ©pendances dans `requirements.txt`.

Ainsi, Ã  partir des mÃªmes donnÃ©es et du mÃªme code, le modÃ¨le produit toujours les mÃªmes rÃ©sultats.

### 5. Quelles seraient les failles de sÃ©curitÃ© Ã  traiter avant un dÃ©ploiement public ?

Avant un dÃ©ploiement rÃ©el, plusieurs points doivent Ãªtre renforcÃ©s :

- **SÃ©curitÃ© de lâ€™authentification** :
  * hashage des mots de passe,
  * gestion sÃ©curisÃ©e des tokens (JWT avec expiration).
- **SÃ©curitÃ© des donnÃ©es utilisateur** :
  - protection des donnÃ©es personnelles (RGPD),
  - limitation de lâ€™accÃ¨s aux donnÃ©es par utilisateur.
- **SÃ©curitÃ© de lâ€™API** :

  - validation stricte des entrÃ©es (Pydantic),
  - protection contre les attaques par injection.
- **SÃ©curitÃ© du modÃ¨le** :

  - contrÃ´le des donnÃ©es envoyÃ©es au modÃ¨le,
  - Ã©viter lâ€™exposition directe du fichier `model.pkl`.
- **Configuration serveur** :

  - gestion correcte des CORS,
  - stockage sÃ©curisÃ© des clÃ©s et secrets.
